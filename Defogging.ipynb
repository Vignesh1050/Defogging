{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b4e84f8-742f-491b-b876-2abf757a1cff",
      "metadata": {
        "id": "7b4e84f8-742f-491b-b876-2abf757a1cff"
      },
      "outputs": [],
      "source": [
        "#LWAF(Method-1)\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def estimate_veiling(image):\n",
        "    dark_prior = np.min(image, axis=2)\n",
        "    veiling = 1 - dark_prior / 255  #\n",
        "    cv2.imshow('Estimated Veiling', (veiling * 255).astype(np.uint8))\n",
        "    cv2.waitKey(0)\n",
        "    return veiling\n",
        "def adaptive_wiener_filter(observation, local_mean, local_variance, noise_variance):\n",
        "    refined_estimate = local_mean + ((local_variance - noise_variance) / local_variance) * (observation - local_mean)\n",
        "    return refined_estimate\n",
        "def calculate_local_variance(image, window_size):\n",
        "    height, width = image.shape\n",
        "    pad = window_size // 2\n",
        "    padded_image = cv2.copyMakeBorder(image, pad, pad, pad, pad, cv2.BORDER_REFLECT)\n",
        "    local_variance = np.zeros_like(image, dtype=np.float32)\n",
        "    for y in range(pad, height + pad):\n",
        "        for x in range(pad, width + pad):\n",
        "            window = padded_image[y - pad:y + pad + 1, x - pad:x + pad + 1]\n",
        "            local_mean = np.mean(window)\n",
        "            local_variance[y - pad, x - pad] = np.mean((window - local_mean) ** 2)\n",
        "    return local_variance\n",
        "def estimate_noise_variance(image):\n",
        "    observation_variances = np.var(image, axis=(0, 1))\n",
        "    noise_variance = np.mean(observation_variances) / (image.shape[0] * image.shape[1])\n",
        "    return noise_variance\n",
        "def defog_image(image, veiling, noise_variance):\n",
        "    window_size = 32\n",
        "    local_mean = cv2.blur(veiling, (window_size, window_size))\n",
        "    local_variance = calculate_local_variance(veiling, window_size)\n",
        "    refined_veiling = adaptive_wiener_filter(veiling, local_mean, local_variance, noise_variance)\n",
        "    cv2.imshow('Refined Veiling Estimate', (refined_veiling * 255).astype(np.uint8))\n",
        "    cv2.waitKey(0)\n",
        "    transmission = 1 - refined_veiling\n",
        "    cv2.imshow('Transmission Map', (transmission * 255).astype(np.uint8))\n",
        "    cv2.waitKey(0)\n",
        "    defogged_image = (image - transmission[..., None] * 255) / np.maximum(transmission[..., None], 0.01) + transmission[..., None] * 255\n",
        "    defogged_image = np.clip(defogged_image, 0, 255).astype(np.uint8)\n",
        "    cv2.imshow('Defogged Image', defogged_image)\n",
        "    cv2.waitKey(0)\n",
        "    return defogged_image\n",
        "\n",
        "foggy_image = cv2.imread('F1.png')\n",
        "cv2.imshow('Foggy Image', foggy_image)\n",
        "cv2.waitKey(0)\n",
        "# Estimate veiling from the foggy image\n",
        "veiling_estimate = estimate_veiling(foggy_image)\n",
        "# Decompose the foggy image into low and high-resolution components\n",
        "low_res_image = cv2.pyrDown(foggy_image)\n",
        "high_res_image = foggy_image - cv2.pyrUp(low_res_image)\n",
        "# Estimate noise variance using the low-resolution component\n",
        "noise_variance = estimate_noise_variance(low_res_image)\n",
        "# Defog the image with the estimated veiling and noise variance\n",
        "defogged_image = defog_image(foggy_image, veiling_estimate, noise_variance)\n",
        "\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbc01278-e0f3-47f4-95cb-cc6df57aaf4e",
      "metadata": {
        "id": "fbc01278-e0f3-47f4-95cb-cc6df57aaf4e"
      },
      "outputs": [],
      "source": [
        "#Guided filter\n",
        "import cv2\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "def DarkChannel(im, sz):\n",
        "    b, g, r = cv2.split(im)\n",
        "    dc = cv2.min(cv2.min(r, g), b)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (sz, sz))\n",
        "    dark = cv2.erode(dc, kernel)\n",
        "    return dark\n",
        "\n",
        "def AtmLight(im, dark):\n",
        "    [h, w] = im.shape[:2]\n",
        "    imsz = h * w\n",
        "    numpx = int(max(math.floor(imsz / 1000), 1))\n",
        "    darkvec = dark.reshape(imsz)\n",
        "    imvec = im.reshape(imsz, 3)\n",
        "    indices = darkvec.argsort()\n",
        "    indices = indices[imsz - numpx::]\n",
        "\n",
        "    atmsum = np.zeros([1, 3])\n",
        "    for ind in range(1, numpx):\n",
        "        atmsum = atmsum + imvec[indices[ind]]\n",
        "    A = atmsum / numpx\n",
        "    return A\n",
        "\n",
        "def TransmissionEstimate(im, A, sz):\n",
        "    omega = 0.95\n",
        "    im3 = np.empty(im.shape, im.dtype)\n",
        "    for ind in range(0, 3):\n",
        "        im3[:, :, ind] = im[:, :, ind] / A[0, ind]\n",
        "    transmission = 1 - omega * DarkChannel(im3, sz)\n",
        "    return transmission\n",
        "\n",
        "def Guidedfilter(im, p, r, eps):\n",
        "    mean_I = cv2.boxFilter(im, cv2.CV_64F, (r, r))\n",
        "    mean_p = cv2.boxFilter(p, cv2.CV_64F, (r, r))\n",
        "    mean_Ip = cv2.boxFilter(im * p, cv2.CV_64F, (r, r))\n",
        "    cov_Ip = mean_Ip - mean_I * mean_p\n",
        "    mean_II = cv2.boxFilter(im * im, cv2.CV_64F, (r, r))\n",
        "    var_I = mean_II - mean_I * mean_I\n",
        "    a = cov_Ip / (var_I + eps)\n",
        "    b = mean_p - a * mean_I\n",
        "    mean_a = cv2.boxFilter(a, cv2.CV_64F, (r, r))\n",
        "    mean_b = cv2.boxFilter(b, cv2.CV_64F, (r, r))\n",
        "    q = mean_a * im + mean_b\n",
        "    return q\n",
        "\n",
        "def TransmissionRefine(im, et):\n",
        "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "    gray = np.float64(gray) / 255\n",
        "    r = 60\n",
        "    eps = 0.0001\n",
        "    t = Guidedfilter(gray, et, r, eps)\n",
        "    return t\n",
        "\n",
        "def Recover(im, t, A, tx=0.1):\n",
        "    res = np.empty(im.shape, im.dtype)\n",
        "    t = cv2.max(t, tx)\n",
        "\n",
        "    for ind in range(0, 3):\n",
        "        res[:, :, ind] = (im[:, :, ind] - A[0, ind]) / t + A[0, ind]\n",
        "    return res\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    dataset_folder = 'Foggy Images'\n",
        "    output_folder = 'output7'\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "    for filename in os.listdir(dataset_folder):\n",
        "        if filename.endswith('.png') or filename.endswith('.jpg'):\n",
        "            input_image = os.path.join(dataset_folder, filename)\n",
        "            src = cv2.imread(input_image)\n",
        "            if src is None:\n",
        "                print(f\"Error: Unable to read the input image '{filename}'.\")\n",
        "                continue\n",
        "            I = src.astype('float64') / 255\n",
        "            dark = DarkChannel(I, 15)\n",
        "            A = AtmLight(I, dark)\n",
        "            te = TransmissionEstimate(I, A, 15)\n",
        "\n",
        "            # Down-sample the rough transmission map and the guidance image\n",
        "            te_downsampled = cv2.resize(te, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_NEAREST)\n",
        "            src_downsampled = cv2.resize(src, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "            cv2.imshow('Transmission Map (Before Refinement with guided filter )', te_downsampled)\n",
        "            cv2.waitKey(0)\n",
        "\n",
        "            t = TransmissionRefine(src_downsampled, te_downsampled)\n",
        "\n",
        "            # Up-sample the refined transmission map\n",
        "            t_upsampled = cv2.resize(t, (src.shape[1], src.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "            J = Recover(I, t_upsampled, A, 0.1)\n",
        "\n",
        "            cv2.imshow('Transmission Map (After Refinement with guided filter)', t_upsampled)\n",
        "            cv2.waitKey(0)\n",
        "            cv2.imshow('Input Image', src)\n",
        "            cv2.waitKey(0)\n",
        "            cv2.imshow('Output Image', J)\n",
        "            cv2.waitKey(0)\n",
        "\n",
        "            # Save the output images\n",
        "            output_image_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_image_path, J * 255)  # Convert back to 0-255 range before saving\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "    print(\"Folder Saved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "def calculate_metrics(input_folder, processed_folder):\n",
        "    input_images = os.listdir(input_folder)\n",
        "    processed_images = os.listdir(processed_folder)\n",
        "    input_images.sort()\n",
        "    processed_images.sort()\n",
        "    for input_image_name, processed_image_name in zip(input_images, processed_images):\n",
        "        input_image_path = os.path.join(input_folder, input_image_name)\n",
        "        processed_image_path = os.path.join(processed_folder, processed_image_name)\n",
        "        input_image = cv2.imread(input_image_path)\n",
        "        processed_image = cv2.imread(processed_image_path)\n",
        "        input_image = cv2.resize(input_image, (processed_image.shape[1], processed_image.shape[0]))\n",
        "        input_gray = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
        "        processed_gray = cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Calculate PSNR\n",
        "        psnr_value = psnr(input_gray, processed_gray)\n",
        "\n",
        "        # Calculate SSIM\n",
        "        ssim_value, _ = ssim(input_gray, processed_gray, full=True)\n",
        "\n",
        "        print(f\"Image: {input_image_name}\")\n",
        "        print(\"PSNR:\", psnr_value)\n",
        "        print(\"SSIM:\", ssim_value)\n",
        "        print(\"=\"*30)\n",
        "\n",
        "input_folder = \"Foggy Images\"\n",
        "processed_folder = \"output7\"\n",
        "calculate_metrics(input_folder, processed_folder)\n",
        "\n"
      ],
      "metadata": {
        "id": "lFMOBiftkWhb"
      },
      "id": "lFMOBiftkWhb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}